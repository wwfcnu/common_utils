import asyncio
import websockets
import uuid
import json
import gzip
import copy
import time
import statistics
from typing import List, Dict
from datetime import datetime

MESSAGE_TYPES = {11: "audio-only server response", 12: "frontend server response", 15: "error message from server"}
MESSAGE_TYPE_SPECIFIC_FLAGS = {0: "no sequence number", 1: "sequence number > 0",
                               2: "last message from server (seq < 0)", 3: "sequence number < 0"}

class BytedanceTTSBenchmark:
    def __init__(self, appid: str, token: str, voice_type: str, cluster: str = "volcano_tts"):
        """
        åˆå§‹åŒ–å­—èŠ‚ TTS å‹æµ‹å·¥å…·
        """
        self.appid = appid
        self.token = token
        self.voice_type = voice_type
        self.cluster = cluster
        self.host = "openspeech.bytedance.com"
        self.api_url = f"wss://{self.host}/api/v1/tts/ws_binary"
        self.results = []
        
        # é»˜è®¤è¯·æ±‚å¤´ï¼ˆåè®®ç‰ˆæœ¬ 1.1ï¼‰
        self.default_header = bytearray(b'\x11\x10\x11\x00')
        
        # åŸºç¡€è¯·æ±‚æ¨¡æ¿
        self.request_json = {
            "app": {
                "appid": self.appid,
                "token": "access_token",
                "cluster": self.cluster
            },
            "user": {
                "uid": "388808087185088"
            },
            "audio": {
                "voice_type": self.voice_type,
                "encoding": "pcm",
                "speed_ratio": 1.0,
                "volume_ratio": 1.0,
                "pitch_ratio": 1.0,
            },
            "request": {
                "reqid": "xxx",
                "text": "xxx",
                "text_type": "plain",
                "operation": "submit",
            }
        }
    
    def build_request(self, text: str) -> bytearray:
        """æ„å»ºè¯·æ±‚æ•°æ®åŒ…"""
        submit_request_json = copy.deepcopy(self.request_json)
        submit_request_json["request"]["reqid"] = str(uuid.uuid4())
        submit_request_json["request"]["text"] = text
        
        payload_bytes = str.encode(json.dumps(submit_request_json))
        payload_bytes = gzip.compress(payload_bytes)
        
        full_client_request = bytearray(self.default_header)
        full_client_request.extend((len(payload_bytes)).to_bytes(4, 'big'))
        full_client_request.extend(payload_bytes)
        
        return full_client_request
    
    def parse_response(self, res: bytes, verbose: bool = False) -> Dict:
        """è§£ææœåŠ¡å™¨å“åº”"""
        protocol_version = res[0] >> 4
        header_size = res[0] & 0x0f
        message_type = res[1] >> 4
        message_type_specific_flags = res[1] & 0x0f
        serialization_method = res[2] >> 4
        message_compression = res[2] & 0x0f
        payload = res[header_size*4:]
        
        result = {
            "message_type": message_type,
            "flags": message_type_specific_flags,
            "payload_size": 0,
            "sequence_number": None,
            "audio_data": None,
            "is_last": False,
            "error": None
        }
        
        if message_type == 0xb:  # audio-only server response
            if message_type_specific_flags == 0:  # ACK
                result["is_ack"] = True
                return result
            else:
                sequence_number = int.from_bytes(payload[:4], "big", signed=True)
                payload_size = int.from_bytes(payload[4:8], "big", signed=False)
                audio_data = payload[8:]
                
                result["sequence_number"] = sequence_number
                result["payload_size"] = payload_size
                result["audio_data"] = audio_data
                result["is_last"] = (sequence_number < 0)
                
                if verbose:
                    print(f"      Seq: {sequence_number}, Size: {payload_size} bytes")
                
                return result
                
        elif message_type == 0xf:  # error
            code = int.from_bytes(payload[:4], "big", signed=False)
            msg_size = int.from_bytes(payload[4:8], "big", signed=False)
            error_msg = payload[8:]
            if message_compression == 1:
                error_msg = gzip.decompress(error_msg)
            error_msg = str(error_msg, "utf-8")
            
            result["error"] = {"code": code, "message": error_msg}
            result["is_last"] = True
            return result
        
        return result
    
    async def single_tts_request(self, text: str, task_id: int, save_audio: bool = False, verbose: bool = False) -> Dict:
        """
        æ‰§è¡Œå•æ¬¡ TTS è¯·æ±‚
        """
        start_time = time.time()
        first_chunk_time = None
        chunks_received = 0
        total_audio_bytes = 0
        chunk_details = []
        last_chunk_time = start_time
        
        output_file = f"benchmark_output_{task_id}.pcm" if save_audio else None
        file_handle = None
        
        try:
            header = {"Authorization": f"Bearer; {self.token}"}
            request_data = self.build_request(text)
            
            async with websockets.connect(self.api_url, extra_headers=header, ping_interval=None) as ws:
                # å‘é€è¯·æ±‚
                await ws.send(request_data)
                
                if save_audio:
                    file_handle = open(output_file, "wb")
                
                # æ¥æ”¶å“åº”
                while True:
                    res = await ws.recv()
                    current_time = time.time()
                    chunk_latency = (current_time - last_chunk_time) * 1000
                    
                    parsed = self.parse_response(res, verbose)
                    
                    # å¤„ç†é”™è¯¯
                    if parsed.get("error"):
                        if file_handle:
                            file_handle.close()
                        return {
                            "task_id": task_id,
                            "success": False,
                            "error": parsed["error"]["message"],
                            "total_latency": 0,
                            "first_chunk_latency": 0
                        }
                    
                    # å¤„ç†éŸ³é¢‘æ•°æ®
                    if parsed.get("audio_data"):
                        if first_chunk_time is None:
                            first_chunk_time = current_time - start_time
                        
                        chunks_received += 1
                        chunk_bytes = parsed["payload_size"]
                        total_audio_bytes += chunk_bytes
                        
                        # è®¡ç®—éŸ³é¢‘åŒ…çš„æŒç»­æ—¶é—´å’Œ RTF
                        # MP3 @ 128kbps: 16000 bytes/sec
                        chunk_duration = chunk_bytes / 48000  # ç§’
                        chunk_rtf = (chunk_latency / 1000) / chunk_duration if chunk_duration > 0 else 0
                        
                        chunk_info = {
                            "chunk_id": chunks_received,
                            "sequence": parsed["sequence_number"],
                            "bytes": chunk_bytes,
                            "latency_ms": chunk_latency,
                            "duration_ms": chunk_duration * 1000,
                            "rtf": chunk_rtf,
                            "timestamp": current_time - start_time
                        }
                        chunk_details.append(chunk_info)
                        
                        if verbose:
                            print(f"    [Task {task_id}] Chunk {chunks_received}: "
                                  f"{chunk_bytes} bytes, "
                                  f"latency {chunk_latency:.1f}ms, "
                                  f"duration {chunk_duration*1000:.1f}ms, "
                                  f"RTF {chunk_rtf:.4f}")
                        
                        if file_handle:
                            file_handle.write(parsed["audio_data"])
                        
                        last_chunk_time = current_time
                    
                    # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                    if parsed.get("is_last"):
                        break
                
                if file_handle:
                    file_handle.close()
                
                total_latency = time.time() - start_time
                
                # è®¡ç®—æ€»ä½“ RTF
                total_audio_duration = total_audio_bytes / 48000  # ç§’
                overall_rtf = total_latency / total_audio_duration if total_audio_duration > 0 else 0
                
                return {
                    "task_id": task_id,
                    "success": True,
                    "total_latency": total_latency * 1000,
                    "first_chunk_latency": first_chunk_time * 1000 if first_chunk_time else 0,
                    "chunks_received": chunks_received,
                    "audio_bytes": total_audio_bytes,
                    "rtf": overall_rtf,
                    "chunk_details": chunk_details
                }
                
        except Exception as e:
            if file_handle:
                file_handle.close()
            return {
                "task_id": task_id,
                "success": False,
                "error": str(e),
                "total_latency": 0,
                "first_chunk_latency": 0
            }
    
    async def run_concurrent_test(self, text: str, concurrent_tasks: int, iterations: int = 10, verbose: bool = False):
        """
        è¿è¡Œå¹¶å‘æµ‹è¯•
        """
        print(f"\n{'='*80}")
        print(f"ğŸš€ æµ‹è¯•å¹¶å‘æ•°: {concurrent_tasks}, è¿­ä»£æ¬¡æ•°: {iterations}")
        print(f"{'='*80}")
        
        all_results = []
        
        for iteration in range(iterations):
            tasks = []
            for i in range(concurrent_tasks):
                task_id = iteration * concurrent_tasks + i
                save_audio = (iteration == 0 and i == 0)
                task = self.single_tts_request(text, task_id, save_audio, verbose)
                tasks.append(task)
            
            iteration_start = time.time()
            results = await asyncio.gather(*tasks)
            iteration_time = time.time() - iteration_start
            
            all_results.extend(results)
            
            successful = sum(1 for r in results if r["success"])
            print(f"  è¿­ä»£ {iteration + 1}/{iterations}: âœ… {successful}/{concurrent_tasks} "
                  f"è€—æ—¶ {iteration_time:.2f}s")
            
            if iteration < iterations - 1:
                await asyncio.sleep(0.5)
        
        # ç»Ÿè®¡ç»“æœ
        successful_results = [r for r in all_results if r["success"]]
        
        if not successful_results:
            print("\nâŒ æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†ï¼")
            failed_results = [r for r in all_results if not r["success"]]
            print(f"å¤±è´¥åŸå› : {failed_results[0].get('error', 'Unknown')}")
            return
        
        total_latencies = [r["total_latency"] for r in successful_results]
        first_chunk_latencies = [r["first_chunk_latency"] for r in successful_results]
        rtf_values = [r["rtf"] for r in successful_results if r.get("rtf", 0) > 0]
        
        # æ”¶é›†æ‰€æœ‰éŸ³é¢‘åŒ…çš„ç»Ÿè®¡
        all_chunk_latencies = []
        all_chunk_rtfs = []
        for r in successful_results:
            if "chunk_details" in r:
                for chunk in r["chunk_details"]:
                    all_chunk_latencies.append(chunk["latency_ms"])
                    all_chunk_rtfs.append(chunk["rtf"])
        
        stats = {
            "concurrent_tasks": concurrent_tasks,
            "total_requests": len(all_results),
            "successful_requests": len(successful_results),
            "failed_requests": len(all_results) - len(successful_results),
            "rtf": statistics.mean(rtf_values) if rtf_values else 0,
            "total_latency": {
                "average": statistics.mean(total_latencies),
                "p50": statistics.median(total_latencies),
                "p90": self.percentile(total_latencies, 90),
                "p95": self.percentile(total_latencies, 95),
                "p99": self.percentile(total_latencies, 99),
            },
            "first_chunk_latency": {
                "average": statistics.mean(first_chunk_latencies),
                "p50": statistics.median(first_chunk_latencies),
                "p90": self.percentile(first_chunk_latencies, 90),
                "p95": self.percentile(first_chunk_latencies, 95),
                "p99": self.percentile(first_chunk_latencies, 99),
            },
            "chunk_latency": {
                "average": statistics.mean(all_chunk_latencies) if all_chunk_latencies else 0,
                "p50": statistics.median(all_chunk_latencies) if all_chunk_latencies else 0,
                "p90": self.percentile(all_chunk_latencies, 90) if all_chunk_latencies else 0,
                "p95": self.percentile(all_chunk_latencies, 95) if all_chunk_latencies else 0,
                "p99": self.percentile(all_chunk_latencies, 99) if all_chunk_latencies else 0,
            },
            "chunk_rtf": {
                "average": statistics.mean(all_chunk_rtfs) if all_chunk_rtfs else 0,
                "p50": statistics.median(all_chunk_rtfs) if all_chunk_rtfs else 0,
                "p90": self.percentile(all_chunk_rtfs, 90) if all_chunk_rtfs else 0,
                "p95": self.percentile(all_chunk_rtfs, 95) if all_chunk_rtfs else 0,
                "p99": self.percentile(all_chunk_rtfs, 99) if all_chunk_rtfs else 0,
            }
        }
        
        self.results.append(stats)
        self.print_stats(stats)
    
    def percentile(self, data: List[float], percentile: int) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]
    
    def print_stats(self, stats: Dict):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"  âœ… æˆåŠŸç‡: {stats['successful_requests']}/{stats['total_requests']} "
              f"({stats['successful_requests']/stats['total_requests']*100:.1f}%)")
        
        if stats['rtf'] > 0:
            print(f"  âš¡ RTF (å®æ—¶å› å­): {stats['rtf']:.4f}")
        
        print(f"\n  ğŸ“ˆ æ€»è¯·æ±‚å»¶è¿Ÿ (Total Request Latency):")
        print(f"     å¹³å‡: {stats['total_latency']['average']:.2f} ms")
        print(f"     P50:  {stats['total_latency']['p50']:.2f} ms")
        print(f"     P90:  {stats['total_latency']['p90']:.2f} ms")
        print(f"     P95:  {stats['total_latency']['p95']:.2f} ms")
        print(f"     P99:  {stats['total_latency']['p99']:.2f} ms")
        
        print(f"\n  âš¡ é¦–å—å»¶è¿Ÿ (First Chunk Latency):")
        print(f"     å¹³å‡: {stats['first_chunk_latency']['average']:.2f} ms")
        print(f"     P50:  {stats['first_chunk_latency']['p50']:.2f} ms")
        print(f"     P90:  {stats['first_chunk_latency']['p90']:.2f} ms")
        print(f"     P95:  {stats['first_chunk_latency']['p95']:.2f} ms")
        print(f"     P99:  {stats['first_chunk_latency']['p99']:.2f} ms")
        
        if stats['chunk_latency']['average'] > 0:
            print(f"\n  ğŸ“¦ å•ä¸ªéŸ³é¢‘åŒ…å»¶è¿Ÿ (Chunk Latency):")
            print(f"     å¹³å‡: {stats['chunk_latency']['average']:.2f} ms")
            print(f"     P50:  {stats['chunk_latency']['p50']:.2f} ms")
            print(f"     P90:  {stats['chunk_latency']['p90']:.2f} ms")
            print(f"     P95:  {stats['chunk_latency']['p95']:.2f} ms")
            print(f"     P99:  {stats['chunk_latency']['p99']:.2f} ms")
        
        if stats['chunk_rtf']['average'] > 0:
            print(f"\n  ğŸ¯ å•ä¸ªéŸ³é¢‘åŒ… RTF (Chunk RTF):")
            print(f"     å¹³å‡: {stats['chunk_rtf']['average']:.4f}")
            print(f"     P50:  {stats['chunk_rtf']['p50']:.4f}")
            print(f"     P90:  {stats['chunk_rtf']['p90']:.4f}")
            print(f"     P95:  {stats['chunk_rtf']['p95']:.4f}")
            print(f"     P99:  {stats['chunk_rtf']['p99']:.4f}")
    
    def print_summary_table(self):
        """æ‰“å°æ±‡æ€»è¡¨æ ¼"""
        print("\n" + "="*140)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
        print("="*140)
        
        print("\n### æ€»è¯·æ±‚å»¶è¿Ÿ (Total Request Latency)\n")
        print(f"| {'å¹¶å‘æ•°':<12} | {'RTF':<10} | {'å¹³å‡ (ms)':<12} | {'50th (ms)':<12} | "
              f"{'90th (ms)':<12} | {'95th (ms)':<12} | {'99th (ms)':<12} |")
        print(f"| {'-'*12} | {'-'*10} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} |")
        
        for stats in self.results:
            print(f"| {stats['concurrent_tasks']:<12} | "
                  f"{stats['rtf']:<10.4f} | "
                  f"{stats['total_latency']['average']:<12.2f} | "
                  f"{stats['total_latency']['p50']:<12.2f} | "
                  f"{stats['total_latency']['p90']:<12.2f} | "
                  f"{stats['total_latency']['p95']:<12.2f} | "
                  f"{stats['total_latency']['p99']:<12.2f} |")
        
        print("\n### é¦–å—å»¶è¿Ÿ (First Chunk Latency)\n")
        print(f"| {'å¹¶å‘æ•°':<12} | {'å¹³å‡ (ms)':<12} | {'50th (ms)':<12} | "
              f"{'90th (ms)':<12} | {'95th (ms)':<12} | {'99th (ms)':<12} |")
        print(f"| {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} |")
        
        for stats in self.results:
            print(f"| {stats['concurrent_tasks']:<12} | "
                  f"{stats['first_chunk_latency']['average']:<12.2f} | "
                  f"{stats['first_chunk_latency']['p50']:<12.2f} | "
                  f"{stats['first_chunk_latency']['p90']:<12.2f} | "
                  f"{stats['first_chunk_latency']['p95']:<12.2f} | "
                  f"{stats['first_chunk_latency']['p99']:<12.2f} |")
        
        if any(stats.get('chunk_latency', {}).get('average', 0) > 0 for stats in self.results):
            print("\n### å•ä¸ªéŸ³é¢‘åŒ…å»¶è¿Ÿ (Chunk Latency)\n")
            print(f"| {'å¹¶å‘æ•°':<12} | {'å¹³å‡ (ms)':<12} | {'50th (ms)':<12} | "
                  f"{'90th (ms)':<12} | {'95th (ms)':<12} | {'99th (ms)':<12} |")
            print(f"| {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} |")
            
            for stats in self.results:
                if 'chunk_latency' in stats:
                    print(f"| {stats['concurrent_tasks']:<12} | "
                          f"{stats['chunk_latency']['average']:<12.2f} | "
                          f"{stats['chunk_latency']['p50']:<12.2f} | "
                          f"{stats['chunk_latency']['p90']:<12.2f} | "
                          f"{stats['chunk_latency']['p95']:<12.2f} | "
                          f"{stats['chunk_latency']['p99']:<12.2f} |")
        
        if any(stats.get('chunk_rtf', {}).get('average', 0) > 0 for stats in self.results):
            print("\n### å•ä¸ªéŸ³é¢‘åŒ… RTF (Chunk RTF)\n")
            print(f"| {'å¹¶å‘æ•°':<12} | {'å¹³å‡':<12} | {'50th':<12} | "
                  f"{'90th':<12} | {'95th':<12} | {'99th':<12} |")
            print(f"| {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} |")
            
            for stats in self.results:
                if 'chunk_rtf' in stats:
                    print(f"| {stats['concurrent_tasks']:<12} | "
                          f"{stats['chunk_rtf']['average']:<12.4f} | "
                          f"{stats['chunk_rtf']['p50']:<12.4f} | "
                          f"{stats['chunk_rtf']['p90']:<12.4f} | "
                          f"{stats['chunk_rtf']['p95']:<12.4f} | "
                          f"{stats['chunk_rtf']['p99']:<12.4f} |")
        
        print("\n" + "="*140)
    
    def save_results(self, filename: str = None):
        """ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"bytedance_tts_benchmark_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {filename}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    # ========== é…ç½®å‚æ•° ==========
    # APPID = "3890413330"
    # TOKEN = "E3vt4URBGVIX_Q4Zg9xFsrsBoXQFSLuB"
    APPID = "8538698484"
    TOKEN = "e4nh25GIHULCTJacsOqXC2PvFyesSZmD"
    VOICE_TYPE = "zh_female_kefunvsheng_mars_bigtts"
    CLUSTER = "volcano_tts"
    
    # æµ‹è¯•æ–‡æœ¬
    TEST_TEXT = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ï¼Œè¯­éŸ³åˆæˆæŠ€æœ¯ä¹Ÿè¶Šæ¥è¶Šè‡ªç„¶æµç•…ã€‚"
    
    # å¹¶å‘æ•°åˆ—è¡¨
    # CONCURRENT_LEVELS = [1, 2, 4, 6, 8, 10]
    CONCURRENT_LEVELS = [1]
    # æ¯ä¸ªå¹¶å‘æ•°çš„æµ‹è¯•æ¬¡æ•°
    ITERATIONS = 5
    
    # æ˜¯å¦è¾“å‡ºè¯¦ç»†çš„éŸ³é¢‘åŒ…ä¿¡æ¯ï¼ˆå»ºè®®åªåœ¨ç¬¬ä¸€ä¸ªå¹¶å‘çº§åˆ«è¾“å‡ºï¼‰
    VERBOSE = True
    
    # ==============================
    
    print("="*140)
    print(f"ğŸ¯ å­—èŠ‚ TTS æ€§èƒ½å‹æµ‹")
    print(f"ğŸ“ API: openspeech.bytedance.com")
    print(f"ğŸ¤ éŸ³è‰²: {VOICE_TYPE}")
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {TEST_TEXT[:50]}...")
    print(f"ğŸ”¢ å¹¶å‘çº§åˆ«: {CONCURRENT_LEVELS}")
    print(f"ğŸ” æ¯çº§è¿­ä»£: {ITERATIONS} æ¬¡")
    print("="*140)
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    benchmark = BytedanceTTSBenchmark(APPID, TOKEN, VOICE_TYPE, CLUSTER)
    
    # è¿è¡Œæµ‹è¯•
    for idx, concurrent_tasks in enumerate(CONCURRENT_LEVELS):
        # åªåœ¨ç¬¬ä¸€ä¸ªå¹¶å‘çº§åˆ«è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        verbose = VERBOSE and (idx == 0)
        await benchmark.run_concurrent_test(TEST_TEXT, concurrent_tasks, ITERATIONS, verbose)
        await asyncio.sleep(2)
    
    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    benchmark.print_summary_table()
    
    # ä¿å­˜ç»“æœ
    benchmark.save_results()


if __name__ == "__main__":
    asyncio.run(main())
import asyncio
import json
import websockets
import uuid
import wave
import time
import statistics
from typing import List, Dict
import os
from datetime import datetime

class WebSocketTTSBenchmark:
    def __init__(self, ws_uri: str, prompt_id: str):
        """
        åˆå§‹åŒ– WebSocket TTS å‹æµ‹å·¥å…·
        :param ws_uri: WebSocket URI
        :param prompt_id: æç¤ºéŸ³é¢‘çš„ ID
        """
        self.ws_uri = ws_uri
        self.prompt_id = prompt_id
        self.results = []
        
    async def single_tts_request(self, text: str, task_id: int, save_audio: bool = False, verbose: bool = False) -> Dict:
        """
        æ‰§è¡Œå•æ¬¡ TTS è¯·æ±‚
        """
        headers = {"Authorization": "Bearer ryvsk3zz73419gkgubrnvufp"}
        
        start_time = time.time()
        first_chunk_time = None
        chunks_received = 0
        total_audio_bytes = 0
        chunk_details = []  # è®°å½•æ¯ä¸ªéŸ³é¢‘åŒ…çš„è¯¦ç»†ä¿¡æ¯
        last_chunk_time = start_time
        
        output_file = f"benchmark_output_{task_id}.wav" if save_audio else None
        wav_out = None
        
        try:
            async with websockets.connect(
                self.ws_uri,
                additional_headers=headers,
                ping_interval=20,
                ping_timeout=300,
                close_timeout=3600,
            ) as websocket:
                
                # å‘é€åˆå§‹é…ç½®
                initial_data = {
                    "prompt_id": self.prompt_id,
                    "speed": 1.0,
                    "stream": True,
                    "request_id": str(uuid.uuid4())
                }
                await websocket.send(json.dumps(initial_data))
                
                # ç­‰å¾…æœåŠ¡å™¨å¼€å§‹ä¿¡å·
                start_response = await websocket.recv()
                start_info = json.loads(start_response)
                
                # å‘é€æ–‡æœ¬
                text_data = {
                    "text_chunk": text,
                    "chunk_id": 0
                }
                await websocket.send(json.dumps(text_data))
                
                # å‘é€ç»“æŸä¿¡å·
                await websocket.send(json.dumps({"signal": "end"}))
                
                # å¦‚æœéœ€è¦ä¿å­˜éŸ³é¢‘ï¼Œæ‰“å¼€ wav æ–‡ä»¶
                if save_audio:
                    wav_out = wave.open(output_file, 'wb')
                    wav_out.setnchannels(1)
                    wav_out.setsampwidth(2)
                    wav_out.setframerate(24000)
                
                # æ¥æ”¶å“åº”
                while True:
                    response = await websocket.recv()
                    
                    if isinstance(response, str):
                        try:
                            msg = json.loads(response)
                            if msg.get("status") == "complete":
                                break
                            elif msg.get("status") == "error":
                                return {
                                    "task_id": task_id,
                                    "success": False,
                                    "error": msg.get('message', 'Unknown error'),
                                    "total_latency": 0,
                                    "first_chunk_latency": 0
                                }
                        except json.JSONDecodeError:
                            pass
                    else:
                        # äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
                        current_time = time.time()
                        chunk_latency = (current_time - last_chunk_time) * 1000  # æ¯«ç§’
                        
                        if first_chunk_time is None:
                            first_chunk_time = current_time - start_time
                        
                        chunks_received += 1
                        chunk_bytes = len(response)
                        total_audio_bytes += chunk_bytes
                        
                        # è®¡ç®—è¿™ä¸ªéŸ³é¢‘åŒ…çš„ RTF
                        chunk_duration = chunk_bytes / (24000 * 2)  # éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
                        chunk_rtf = (chunk_latency / 1000) / chunk_duration if chunk_duration > 0 else 0
                        
                        # è®°å½•éŸ³é¢‘åŒ…è¯¦æƒ…
                        chunk_info = {
                            "chunk_id": chunks_received,
                            "bytes": chunk_bytes,
                            "latency_ms": chunk_latency,
                            "duration_ms": chunk_duration * 1000,
                            "rtf": chunk_rtf,
                            "timestamp": current_time - start_time
                        }
                        chunk_details.append(chunk_info)
                        
                        # è¯¦ç»†è¾“å‡ºæ¨¡å¼
                        if verbose:
                            print(f"    [Task {task_id}] Chunk {chunks_received}: "
                                  f"{chunk_bytes} bytes, "
                                  f"latency {chunk_latency:.1f}ms, "
                                  f"duration {chunk_duration*1000:.1f}ms, "
                                  f"RTF {chunk_rtf:.4f}")
                        
                        last_chunk_time = current_time
                        
                        if wav_out:
                            wav_out.writeframes(response)
                
                if wav_out:
                    wav_out.close()
                
                total_latency = time.time() - start_time
                
                return {
                    "task_id": task_id,
                    "success": True,
                    "total_latency": total_latency * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
                    "first_chunk_latency": first_chunk_time * 1000 if first_chunk_time else 0,
                    "chunks_received": chunks_received,
                    "audio_bytes": total_audio_bytes,
                    "rtf": self.calculate_rtf(total_latency, total_audio_bytes),
                    "chunk_details": chunk_details  # æ·»åŠ è¯¦ç»†çš„éŸ³é¢‘åŒ…ä¿¡æ¯
                }
                
        except websockets.exceptions.ConnectionClosed as e:
            return {
                "task_id": task_id,
                "success": False,
                "error": f"Connection closed: {str(e)}",
                "total_latency": 0,
                "first_chunk_latency": 0
            }
        except Exception as e:
            return {
                "task_id": task_id,
                "success": False,
                "error": str(e),
                "total_latency": 0,
                "first_chunk_latency": 0
            }
        finally:
            if wav_out:
                wav_out.close()
                if not save_audio and output_file and os.path.exists(output_file):
                    os.remove(output_file)
    
    def calculate_rtf(self, processing_time: float, audio_bytes: int) -> float:
        """
        è®¡ç®—å®æ—¶å› å­ (Real-Time Factor)
        :param processing_time: å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
        :param audio_bytes: éŸ³é¢‘å­—èŠ‚æ•°
        :return: RTF å€¼
        """
        if audio_bytes == 0:
            return 0
        
        # å‡è®¾é‡‡æ ·ç‡ 24000Hz, 16-bit (2 bytes), å•å£°é“
        audio_duration = audio_bytes / (24000 * 2)  # éŸ³é¢‘å®é™…æ—¶é•¿ï¼ˆç§’ï¼‰
        
        if audio_duration == 0:
            return 0
        
        return processing_time / audio_duration
    
    async def run_concurrent_test(self, text: str, concurrent_tasks: int, iterations: int = 10, verbose: bool = False):
        """
        è¿è¡Œå¹¶å‘æµ‹è¯•
        :param text: è¦åˆæˆçš„æ–‡æœ¬
        :param concurrent_tasks: å¹¶å‘ä»»åŠ¡æ•°
        :param iterations: æ¯ä¸ªå¹¶å‘æ•°çš„æµ‹è¯•æ¬¡æ•°
        :param verbose: æ˜¯å¦è¾“å‡ºæ¯ä¸ªéŸ³é¢‘åŒ…çš„è¯¦ç»†ä¿¡æ¯
        """
        print(f"\n{'='*80}")
        print(f"ğŸš€ æµ‹è¯•å¹¶å‘æ•°: {concurrent_tasks}, è¿­ä»£æ¬¡æ•°: {iterations}")
        print(f"{'='*80}")
        
        all_results = []
        
        for iteration in range(iterations):
            tasks = []
            for i in range(concurrent_tasks):
                task_id = iteration * concurrent_tasks + i
                # åªåœ¨ç¬¬ä¸€æ¬¡è¿­ä»£çš„ç¬¬ä¸€ä¸ªä»»åŠ¡ä¿å­˜éŸ³é¢‘æ ·æœ¬
                save_audio = (iteration == 0 and i == 0)
                # æ‰€æœ‰è¿­ä»£éƒ½è¾“å‡ºè¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœ verbose=Trueï¼‰
                task = self.single_tts_request(text, task_id, save_audio, verbose)
                tasks.append(task)
            
            iteration_start = time.time()
            results = await asyncio.gather(*tasks)
            iteration_time = time.time() - iteration_start
            
            all_results.extend(results)
            
            # æ‰“å°è¿›åº¦
            successful = sum(1 for r in results if r["success"])
            print(f"  è¿­ä»£ {iteration + 1}/{iterations}: âœ… {successful}/{concurrent_tasks} "
                  f"è€—æ—¶ {iteration_time:.2f}s")
            
            # é¿å…è¿‡è½½ï¼Œè¿­ä»£é—´ç¨ä½œåœé¡¿
            if iteration < iterations - 1:
                await asyncio.sleep(0.5)
        
        # ç»Ÿè®¡ç»“æœ
        successful_results = [r for r in all_results if r["success"]]
        
        if not successful_results:
            print("\nâŒ æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†ï¼")
            failed_results = [r for r in all_results if not r["success"]]
            print(f"å¤±è´¥åŸå› : {failed_results[0].get('error', 'Unknown')}")
            return
        
        total_latencies = [r["total_latency"] for r in successful_results]
        first_chunk_latencies = [r["first_chunk_latency"] for r in successful_results]
        rtf_values = [r["rtf"] for r in successful_results if r.get("rtf", 0) > 0]
        
        # æ”¶é›†æ‰€æœ‰éŸ³é¢‘åŒ…çš„ç»Ÿè®¡ä¿¡æ¯
        all_chunk_latencies = []
        all_chunk_rtfs = []
        for r in successful_results:
            if "chunk_details" in r:
                for chunk in r["chunk_details"]:
                    all_chunk_latencies.append(chunk["latency_ms"])
                    all_chunk_rtfs.append(chunk["rtf"])
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        stats = {
            "concurrent_tasks": concurrent_tasks,
            "total_requests": len(all_results),
            "successful_requests": len(successful_results),
            "failed_requests": len(all_results) - len(successful_results),
            "rtf": statistics.mean(rtf_values) if rtf_values else 0,
            "total_latency": {
                "average": statistics.mean(total_latencies),
                "p50": statistics.median(total_latencies),
                "p90": self.percentile(total_latencies, 90),
                "p95": self.percentile(total_latencies, 95),
                "p99": self.percentile(total_latencies, 99),
            },
            "first_chunk_latency": {
                "average": statistics.mean(first_chunk_latencies),
                "p50": statistics.median(first_chunk_latencies),
                "p90": self.percentile(first_chunk_latencies, 90),
                "p95": self.percentile(first_chunk_latencies, 95),
                "p99": self.percentile(first_chunk_latencies, 99),
            },
            "chunk_latency": {
                "average": statistics.mean(all_chunk_latencies) if all_chunk_latencies else 0,
                "p50": statistics.median(all_chunk_latencies) if all_chunk_latencies else 0,
                "p90": self.percentile(all_chunk_latencies, 90) if all_chunk_latencies else 0,
                "p95": self.percentile(all_chunk_latencies, 95) if all_chunk_latencies else 0,
                "p99": self.percentile(all_chunk_latencies, 99) if all_chunk_latencies else 0,
            },
            "chunk_rtf": {
                "average": statistics.mean(all_chunk_rtfs) if all_chunk_rtfs else 0,
                "p50": statistics.median(all_chunk_rtfs) if all_chunk_rtfs else 0,
                "p90": self.percentile(all_chunk_rtfs, 90) if all_chunk_rtfs else 0,
                "p95": self.percentile(all_chunk_rtfs, 95) if all_chunk_rtfs else 0,
                "p99": self.percentile(all_chunk_rtfs, 99) if all_chunk_rtfs else 0,
            }
        }
        
        self.results.append(stats)
        self.print_stats(stats)
        
    def percentile(self, data: List[float], percentile: int) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]
    
    def print_stats(self, stats: Dict):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"  âœ… æˆåŠŸç‡: {stats['successful_requests']}/{stats['total_requests']} "
              f"({stats['successful_requests']/stats['total_requests']*100:.1f}%)")
        
        if stats['rtf'] > 0:
            print(f"  âš¡ RTF (å®æ—¶å› å­): {stats['rtf']:.4f}")
        
        print(f"\n  ğŸ“ˆ æ€»è¯·æ±‚å»¶è¿Ÿ (Total Request Latency):")
        print(f"     å¹³å‡: {stats['total_latency']['average']:.2f} ms")
        print(f"     P50:  {stats['total_latency']['p50']:.2f} ms")
        print(f"     P90:  {stats['total_latency']['p90']:.2f} ms")
        print(f"     P95:  {stats['total_latency']['p95']:.2f} ms")
        print(f"     P99:  {stats['total_latency']['p99']:.2f} ms")
        
        print(f"\n  âš¡ é¦–å—å»¶è¿Ÿ (First Chunk Latency):")
        print(f"     å¹³å‡: {stats['first_chunk_latency']['average']:.2f} ms")
        print(f"     P50:  {stats['first_chunk_latency']['p50']:.2f} ms")
        print(f"     P90:  {stats['first_chunk_latency']['p90']:.2f} ms")
        print(f"     P95:  {stats['first_chunk_latency']['p95']:.2f} ms")
        print(f"     P99:  {stats['first_chunk_latency']['p99']:.2f} ms")
        
        if stats['chunk_latency']['average'] > 0:
            print(f"\n  ğŸ“¦ å•ä¸ªéŸ³é¢‘åŒ…å»¶è¿Ÿ (Chunk Latency):")
            print(f"     å¹³å‡: {stats['chunk_latency']['average']:.2f} ms")
            print(f"     P50:  {stats['chunk_latency']['p50']:.2f} ms")
            print(f"     P90:  {stats['chunk_latency']['p90']:.2f} ms")
            print(f"     P95:  {stats['chunk_latency']['p95']:.2f} ms")
            print(f"     P99:  {stats['chunk_latency']['p99']:.2f} ms")
        
        if stats['chunk_rtf']['average'] > 0:
            print(f"\n  ğŸ¯ å•ä¸ªéŸ³é¢‘åŒ… RTF (Chunk RTF):")
            print(f"     å¹³å‡: {stats['chunk_rtf']['average']:.4f}")
            print(f"     P50:  {stats['chunk_rtf']['p50']:.4f}")
            print(f"     P90:  {stats['chunk_rtf']['p90']:.4f}")
            print(f"     P95:  {stats['chunk_rtf']['p95']:.4f}")
            print(f"     P99:  {stats['chunk_rtf']['p99']:.4f}")
    
    def print_summary_table(self):
        """æ‰“å°æ±‡æ€»è¡¨æ ¼"""
        print("\n" + "="*140)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
        print("="*140)
        
        print("\n### æ€»è¯·æ±‚å»¶è¿Ÿ (Total Request Latency)\n")
        print(f"| {'å¹¶å‘æ•°':<12} | {'RTF':<10} | {'å¹³å‡ (ms)':<12} | {'50th (ms)':<12} | "
              f"{'90th (ms)':<12} | {'95th (ms)':<12} | {'99th (ms)':<12} |")
        print(f"| {'-'*12} | {'-'*10} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} |")
        
        for stats in self.results:
            print(f"| {stats['concurrent_tasks']:<12} | "
                  f"{stats['rtf']:<10.4f} | "
                  f"{stats['total_latency']['average']:<12.2f} | "
                  f"{stats['total_latency']['p50']:<12.2f} | "
                  f"{stats['total_latency']['p90']:<12.2f} | "
                  f"{stats['total_latency']['p95']:<12.2f} | "
                  f"{stats['total_latency']['p99']:<12.2f} |")
        
        print("\n### é¦–å—å»¶è¿Ÿ (First Chunk Latency)\n")
        print(f"| {'å¹¶å‘æ•°':<12} | {'å¹³å‡ (ms)':<12} | {'50th (ms)':<12} | "
              f"{'90th (ms)':<12} | {'95th (ms)':<12} | {'99th (ms)':<12} |")
        print(f"| {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} | {'-'*12} |")
        
        for stats in self.results:
            print(f"| {stats['concurrent_tasks']:<12} | "
                  f"{stats['first_chunk_latency']['average']:<12.2f} | "
                  f"{stats['first_chunk_latency']['p50']:<12.2f} | "
                  f"{stats['first_chunk_latency']['p90']:<12.2f} | "
                  f"{stats['first_chunk_latency']['p95']:<12.2f} | "
                  f"{stats['first_chunk_latency']['p99']:<12.2f} |")
        
        print("\n" + "="*140)
    
    def save_results(self, filename: str = None):
        """ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"benchmark_results_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {filename}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    # ========== é…ç½®å‚æ•° ==========
    # WebSocket URI
    WS_URI = "wss://platform-bj.wair.ac.cn/maas/ws/zero_shot_tts"
    # WS_URI = "ws://172.16.10.5:8080/zeroshot_stream_tts" 
    # Prompt ID (éœ€è¦å…ˆé€šè¿‡ get_prompt_id è·å–)
    PROMPT_ID = "cosyvoice_gan_cb9829cf2c050996eeed620c7acb58ef"  # æ›¿æ¢ä¸ºå®é™…çš„ prompt_id
    # PROMPT_ID = "cosyvoice_gan_4a10f32ecb713d4cd6e93a54ac4f4129" # node10æœ¬åœ°
    # PROMPT_ID = "cosyvoice_flow_d6f48bd7288d3a02e5ea65d98a602212"
    # æµ‹è¯•æ–‡æœ¬
    # TEST_TEXT = "ç³»åˆ—åŠ¨ç”»ç‰‡ã€Šä¸­å›½å¥‡è°­ã€‹å¦‚ä½•è¡ç”Ÿå‡ºå¤§ç”µå½±ã€Šæµªæµªå±±å°å¦–æ€ªã€‹ï¼Ÿæ–°çš„æ•…äº‹é‡Œï¼Œæ›¾è¢«ä¼—å¤šé’å¹´è§‚ä¼—å…±æƒ…çš„å°çŒªå¦–ï¼Œæœ‰å“ªäº›æˆé•¿å˜åŒ–ã€‚"
    TEST_TEXT = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ï¼Œè¯­éŸ³åˆæˆæŠ€æœ¯ä¹Ÿè¶Šæ¥è¶Šè‡ªç„¶æµç•…ã€‚"
    
    # å¹¶å‘æ•°åˆ—è¡¨
    CONCURRENT_LEVELS = [1, 2, 4, 6, 8, 10]
    CONCURRENT_LEVELS = [10]
    # æ¯ä¸ªå¹¶å‘æ•°çš„æµ‹è¯•æ¬¡æ•°
    ITERATIONS = 5
    
    # ==============================
    
    print("="*140)
    print(f"ğŸ¯ WebSocket TTS æ€§èƒ½å‹æµ‹")
    print(f"ğŸ“ URI: {WS_URI}")
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {TEST_TEXT[:50]}...")
    print(f"ğŸ”¢ å¹¶å‘çº§åˆ«: {CONCURRENT_LEVELS}")
    print(f"ğŸ” æ¯çº§è¿­ä»£: {ITERATIONS} æ¬¡")
    print("="*140)
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    benchmark = WebSocketTTSBenchmark(WS_URI, PROMPT_ID)
    
    # è¿è¡Œæµ‹è¯•
    for concurrent_tasks in CONCURRENT_LEVELS:
        # ç¬¬ä¸€ä¸ªå¹¶å‘çº§åˆ«æ˜¾ç¤ºè¯¦ç»†çš„éŸ³é¢‘åŒ…ä¿¡æ¯
        verbose = (concurrent_tasks == CONCURRENT_LEVELS[0])
        await benchmark.run_concurrent_test(TEST_TEXT, concurrent_tasks, ITERATIONS, verbose)
        # ä¸¤æ¬¡æµ‹è¯•ä¹‹é—´æš‚åœï¼Œé¿å…è¿‡è½½
        await asyncio.sleep(2)
    
    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    benchmark.print_summary_table()
    
    # ä¿å­˜ç»“æœ
    benchmark.save_results()


if __name__ == "__main__":
    # è¿è¡Œä¸»å‡½æ•°
    asyncio.run(main())